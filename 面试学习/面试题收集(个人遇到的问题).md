

# 									面试问题收集处

## Java基础：

#### 	1.Java 中浅拷贝和深拷贝的区别，以及实现方式    (https://www.cnblogs.com/shakinghead/p/7651502.html)

​	浅拷贝：对于基本数据类型，会直接进行值传递，也就是将该数据复制一份给新的对象。这时两份数据分属不同的地址，两者互不影响。而对于引用数据类型的变量(对象)，那么浅拷贝则进行引用传递，也就是两者指向同一个内存地址。在这种情况下，修改任何一个对象的属性将会影响到另一个对象

​	

​	深拷贝：相当于开辟新的内存地址，创建了一个相同属性、方法的对象，但地址不同，两者之间没有实际关联。





浅拷贝的实现方式：

​	(1)  通过拷贝构造方法实现浅拷贝：拷贝构造方法指的是该类的构造方法参数为该类的对象。使用拷贝构造方法可以很好地完成浅拷贝，直接通过一个现有的对象创建出与该对象属性相同的新的对象

```java
//拷贝构造方法
    public Person(Person p) {
        this.name=p.name;
        this.age=p.age;
    }
```

​	(2) 重写 clone() 方法进行浅拷贝： Object类中有一个 colne方法，但使用该方法需要实现Cloneable接口，否则会抛出异常CloneNotSupportedException

​	解决方法是，在要使用clone方法的类中重写clone()方法，通过super.clone()调用Object类中的原clone方法。

```java
 //重写Object类的clone方法
    public Object clone() {
        Object obj=null;
        //调用Object类的clone方法，返回一个Object实例
        try {
            obj= super.clone();
        } catch (CloneNotSupportedException e) {
            e.printStackTrace();
        }
        return obj;
    }
```



深拷贝的实现方式：

​	（1） 重写clone() 方法 实现Cloneable接口。

​		(2)  通过序列化 实现深拷贝：将对象序列化为字节序列后，默认会将该对象的整个对象图进行序列化，再通过反序列即可完美地实现深拷贝。

```java
//通过序列化方法实现深拷贝	
		ByteArrayOutputStream bos=new ByteArrayOutputStream();
        ObjectOutputStream oos=new ObjectOutputStream(bos);
        oos.writeObject(target);   //target为需要序列化的对象
        oos.flush();
        ObjectInputStream ois=new ObjectInputStream(new ByteArrayInputStream(bos.toByteArray()));
        Student stu2=(Student)ois.readObject();
```



需要注意的一个点：如果某个属性被**transient** 关键字所修饰，那么就无法序列化从而进行拷贝了 (transient的作用：使修饰的属性的生命周期仅存于调用者的内存中而不会写到磁盘里持久化。)

------



#### 2.( IO流 )序列化了解过吗？说说实现方式   （https://www.cnblogs.com/9dragon/p/10901448.html）

​	序列化：将对象写入IO流中（ 另一种说法是：把 Java对象转换为字节序列的过程 ）

​	反序列化：从IO流中恢复对象 （ 另一种说法是：把字节序列恢复为 JAVA对象的过程 ）



背景：**为什么要有序列化以及什么是序列化？**——在系统下次启动后，某对象需要恢复到上次的状态时，这时需要考虑“**持久化**”该对象。   而持久化则会想到数据库或者缓存。除此之外，若以**注重面向对象的思维**来持久化对象，也就是**基于对象能够在程序不运行的情况下仍能存在并保存其信息的需求**，故对象的序列化功能从而诞生。（简单理解：对象不只是存储于**内存**中，它还需要在传输网络中进行传输，并且保存起来后反序列化进行恢复）

**什么是序列化**？——把**对象转换成一串由二进制字节组成的数组**，然后将这二进制数据保存在磁盘或传输网络(  熟悉的 IO 流操作 )



**意义：序列化机制允许将实现序列化的Java对象转换位字节序列，这些字节序列可以保存在磁盘上，或通过网络传输，以达到以后恢复成原来的对象。序列化机制使得对象可以脱离程序的运行而独立存在。**

使用场景：所有可在网络上传输的对象都必须是可序列化的。比如RMI（remote method invoke,即**远程方法调用**），传入的参数或返回的对象都是可序列化的，否则会出错；**所有需要保存到磁盘的java对象都必须是可序列化的。通常建议：程序创建的每个JavaBean类都实现Serializeable接口。**



**序列化版本号的作用**：java 序列化提供了一个 **private static final long serialVersionUID** 的序列化版本号，只有版本号相同才能进行反序列化。如果反序列化使用的**class的版本号**与序列化时使用的**不一致**，反序列化会报**InvalidClassException异常。**

**序列化版本号可自由指定，如果不指定，JVM会根据类信息自己计算一个版本号，这样随着class的升级，就无法正确反序列化；不指定版本号另一个明显隐患是，不利于jvm间的移植，可能class文件没有更改，但不同jvm可能计算的规则不一样，这样也会导致无法反序列化。**



序列化的**实现方式**： 需要将某个对象保存到磁盘上或者通过网络传输，那么该对象需要**实现Serializable接口或者Externalizable接口**。

​	①实现Serializable接口。Serializable接口是一个标记接口，不用实现任何方法，一旦实现该接口，该类的对象就是可序列化的。且会有一个序列化的版本号，**用来区分我们所编写的类的版本**，用于反序列化时确定版本。

​	**序列化步骤：**

​				步骤一：创建一个**ObjectOutputStream** 输出流。

​				步骤二：调用ObjectOutputStream对象的**writeObject**输入可序列化对象。

​	

​	反序列化步骤：

​				步骤一：创建一个ObjectInputStream输入流。

​				步骤二：调用ObjectInputStream对象的readObject()输出反序列化对象。

​	

② 实现 **Externalizable** 接口：强制自定义序列化。通过实现Externalizable接口，必须实现writeExternal、readExternal方法。

需要注意 **Externalizable接口不同于Serializable接口，实现此接口必须实现接口中的两个方法实现自定义序列化，这是强制性的；特别之处是必须提供pulic的无参构造器，因为在反序列化的时候需要反射创建对象**。



注意点：① **反序列化并不会调用构造方法。反序列的对象是由JVM自己生成的对象，不通过构造方法生成。**

​				② **成员是引用的序列化**。这里指：一个可序列化的类，当其成员变量既不是基本类型、也不是String类型，那么这个**成员变量**（既不是基本类型，也不是String类型，那么就只能是引用类型了）必须是**可序列化的**。

​				③  **同一对象序列化多次的机制**：序列化同一对象，并不会将此对象序列化多次得到多个对象。

​					序列化算法：(1) 所有保存到磁盘上的对象都有一个**序列化编码号**。

​											(2) 当程序试图序列化一个对象时，会先检查此对象是否已序列化过，只有此对象从未在虚拟机中被序列化过，才会将此对象序列化为字											节序列输出。

​											(3) 如果此对象已经序列化过，直接输出序列化编号即可。

​					**序列化算法存在的问题**：由上述可知，**同一个对象不会被重复序列化**。这样如果**已序列化对象的内容被更改后**，**再次序列化，并不会再次将此对象转换为字节序列，而只是保存序列化编号。**

​				④ **可选的自定义序列化**：可以使用关键字 **transient** 来选择不需要序列化的字段。或通过重写 writeObject() 和 readObject() 来选择哪些需要序列化的字段。

​				

```java
 
import java.io.*;

public class Person implements Serializable {
    private String name;
    private int age;
    //我不提供无参构造器
    public Person(String name, int age) {
        this.name = name;
        this.age = age;
    }

    @Override
    public String toString() {
        return "Person{" +
                "name='" + name + '\'' +
                ", age=" + age +
                '}';
    }
}

//序列化将对象转换成一串由二进制字节组成的数组并写入文件中，在文件中看到的是一串乱码，这是二进制输出无需担心。在反序列化能得到理想结果即可
 class WriteObject {
    public static void main(String[] args) {
        try (//创建一个ObjectOutputStream输出流
             ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream("D:\\object.txt"))) {
            //将对象序列化到文件s
            Person person = new Person("9龙", 23);
            oos.writeObject(person);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}

//反序列化，将文件中的二进制字节数组转换成对象并赋予，输出时和 序列化时输入的对象属性等相同
  class ReadObject {
    public static void main(String[] args) {
        try (//创建一个ObjectInputStream输入流
             ObjectInputStream ois = new ObjectInputStream(new FileInputStream("D:\\object.txt"))) {
            Person brady = (Person) ois.readObject();
            System.out.println(brady);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}

```



**序列化的过程**(  **重要**)：**递归写入**的过程。

![](C:\Users\AWU\Desktop\面试学习\面试题整理图片存储池\序列化原理过程.png)

**总结**：①所有需要网络传输的对象都需要实现序列化接口，通过建议所有的javaBean都实现Serializable接口

​			②对象的类名、实例变量（包括基本类型，数组，对其他对象的引用）都会被序列化；方法、类变量、transient实例变量都不会被序列化

​			③如果想让某个变量不被序列化，使用transient修饰

​			④序列化对象的引用类型成员变量，也必须是可序列化的，否则，会报错

​			⑤反序列化时必须有序列化对象的class文件

​			⑥当通过文件、网络来读取序列化后的对象时，必须按照实际写入的顺序读取

​			⑦单例类序列化，需要重写readResolve()方法；否则会破坏单例原则

​			⑧同一对象序列化多次，只有第一次序列化为二进制流，以后都只是保存序列化编号，不会重复序列化

​			⑨建议所有可序列化的类加上serialVersionUID 版本号，方便项目升级





这里有个补充问题：**transient修饰的变量真的就不能被序列化了吗？**

​		在java中，对象序列化可以通过实现两种接口来实现：

- 如果实现的是**Serializable**接口，则所有信息（不包括被static、transient修饰的变量信息）的序列化将**自动**进行。
- 如果实现的是**Externalizable**接口，则不会进行自动序列化，需要开发者在**writeExternal()\**方法中\**手工**指定需要序列化的变量，与是否被transient修饰无关。







#### 3.(集合类) 说一下HashMap

​	具体前往 md文档 **集合类**中查看。





#### 4.(集合类)  集合类能否一边遍历？一边删除，可以的话应该如何实现？不能的话又是什么原因？

```java

    public static void main(String[] args) {
        List<String> platformList = new ArrayList<>();
        platformList.add("博客园");
        platformList.add("CSDN");
        platformList.add("掘金");

        for (String platform : platformList) {
            if (platform.equals("博客园")) {
                platformList.remove(platform);
            }
        }

        System.out.println(platformList);

    }
```

如上述的代码，运行后会出现如下图所示的并发问题：ConcurrentModificationException（并发修改异常）

![集合类的一边遍历一边删除操作](C:\Users\AWU\Desktop\面试学习\面经问题图片存储池\集合类的一边遍历一边删除操作.png)

通过debug(Alt+Shift+F7强制进入) 可以发现，foreach循环在实际执行时，使用的是Iterator 类，其核心方法是hasNext() next()。

本次测试用例为ArrayList类，其内有实现了Iterator接口的Itr私有内部类。

```java
   private class Itr implements Iterator<E> {
        int cursor;       // index of next element to return
        int lastRet = -1; // index of last element returned; -1 if no such
        int expectedModCount = modCount;

        Itr() {}

        public boolean hasNext() {
            return cursor != size;
        }

        @SuppressWarnings("unchecked")
        public E next() {
            checkForComodification();
            int i = cursor;
            if (i >= size)
                throw new NoSuchElementException();
            Object[] elementData = ArrayList.this.elementData;
            if (i >= elementData.length)
                throw new ConcurrentModificationException();
            cursor = i + 1;
            return (E) elementData[lastRet = i];
        }
```



![ArrayList中的Itr类](C:\Users\AWU\Desktop\面试学习\面经问题图片存储池\ArrayList中的Itr类.png)

```java
//一个检测并发修改是否异常的方法，也是上例代码中报错bug所在处
final void checkForComodification() {
            if (modCount != expectedModCount)
                throw new ConcurrentModificationException();
        }	
```

可以看到，checkForComodification() 方法的核心逻辑是：比较expectedModCount和modCount这两个变量的值。

```java
//此列表在结构上被修改的次数。 结构修改是改变列表的大小，或者以其他方式扰乱它，以致正在进行的迭代可能会产生不正确的结果。
//一个短暂的变量(transient)且只在包内产生作用(protected)   
protected transient int modCount = 0;

```

而modCount是如何增加的呢？可以看到，add()方法中每次添加一个元素，会使得modCount++自增。具体看如下代码：

```java
public void add(int index, E element) {
        rangeCheckForAdd(index);

        ensureCapacityInternal(size + 1);  // Increments modCount!!
        System.arraycopy(elementData, index, elementData, index + 1,
                         size - index);
        elementData[index] = element;
        size++;
    }

//封装
private void ensureCapacityInternal(int minCapacity) {
   ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));
    }

//ensureExplicitCapacity()方法中进行了modCount的自增
  private void ensureExplicitCapacity(int minCapacity) {
        modCount++;

        // overflow-conscious code
        if (minCapacity - elementData.length > 0)
            grow(minCapacity);
    }

```

所以，根据源代码可知，上述用例中未进行删除操作前，modCount和expectedModCount的值都为3，但进行删除操作时，会有什么变化呢？可以先理解一下remove() 方法：

```java
public E remove(int index) {
        rangeCheck(index);

        modCount++;
        E oldValue = elementData(index);

        int numMoved = size - index - 1;
        if (numMoved > 0)
            System.arraycopy(elementData, index+1, elementData, index,
                             numMoved);
        elementData[--size] = null; // clear to let GC do its work

        return oldValue;
    }
```

如上，从源代码中可知，当进行了删除操作，modCount会自增一次(modCount是记录**修改的次数**，故是进行自增)，于是在遍历得到对应要删除的值时，进行删除操作后modCount将为4，与expectedModCount 不等，所以会抛出**并发修改异常( ConcurrentModificationException )**。



既然不能使用foreach来实现，那么该如何实现呢？

​	主要有**三种**方法。——

​		① 使用Iterator 的remove() 方法。

​		② 使用for循环正序遍历

​		③ 使用for循环倒叙遍历

对于第一种方法，使用Iterator接口来实现遍历删除操作。首先需要明白，Iterator是一个接口，不能作为一个实例对象实现，必须通过被它实现的类来进行实例化操作。然后通过类来指向对应的方法中。

```java
public static void main(String[] args) {
    List<String> platformList = new ArrayList<>();
    platformList.add("博客园");
    platformList.add("CSDN");
    platformList.add("掘金");

    Iterator<String> iterator = platformList.iterator();
    while (iterator.hasNext()) {
        String platform = iterator.next();
        if (platform.equals("博客园")) {
            iterator.remove();
        }
    }

    System.out.println(platformList);
}
```

该方法可以实现，是因为在remove方法中，进行了expectedModCount的重新赋值。如下源代码可看出：

```java
public void remove() {
            if (lastRet < 0)
                throw new IllegalStateException();
            checkForComodification();

            try {
                ArrayList.this.remove(lastRet);
                cursor = lastRet;
                lastRet = -1;
                expectedModCount = modCount;  //重点地方
            } catch (IndexOutOfBoundsException ex) {
                throw new ConcurrentModificationException();
            }
        }
```

可以看到，只要调用了remove() 方法，就会将modCount的值重新赋值给expectedModCount，故两个变量相等则不会出现并发修改异常(ConcurrentModificationException)。



对于第二种方法，使用for循环进行正序遍历，

```java
public static void main(String[] args) {
    List<String> platformList = new ArrayList<>();
    platformList.add("博客园");
    platformList.add("CSDN");
    platformList.add("掘金");

    for (int i = 0; i < platformList.size(); i++) {
        String item = platformList.get(i);

        if (item.equals("博客园")) {
            platformList.remove(i);
            i = i - 1;
        }
    }

    System.out.println(platformList);
}
```

通过数组的下标来删除元素，但需要明白一点，当你删除当前数组下标元素，后面的元素将会向前移，而此刻将会i++，所以要进行一次i--的操作。



对于第三种方法，使用for循环进行倒序遍历：

```java
public static void main(String[] args) {
    List<String> platformList = new ArrayList<>();
    platformList.add("博客园");
    platformList.add("CSDN");
    platformList.add("掘金");

    for (int i = platformList.size() - 1; i >= 0; i--) {
        String item = platformList.get(i);

        if (item.equals("掘金")) {
            platformList.remove(i);
        }
    }

    System.out.println(platformList);
}
```

这里不需要修正下标，因为从后往前查找删除元素，并不会影响到前面元素的查找。



#### 5.接口和抽象类的区别，以及各自的使用场景.

​	首先，了解一下各自的特点。

​		如接口，接口是**一个规范、一个抽象类型，是抽象方法的集合**。( 例如  某种事物对外提供的一些功能的说明 )。接口以interface来声明，且Java以**接口实现多态**的功能来弥补了单一继承的缺陷。(通过接口可以多实现，从而使得Java单一继承类、多实现接口)。由于接口**不能直接实例化，只能通过引用**，也就是说需要通过实现了接口的实现类来实例化对象才能使用接口的功能。**在interface中所有的方法都是public abstract的，即使你没有申明它是public  abstract的。在interface中所有的数据成员都是public static final的，即使你没有申明.但不能是blank  final 在编译时候确定的**。

​		如抽象类，由abstract修饰的类就叫抽象类。官方给的定义是：如果**一个类没有包含足够多的信息来描述一个具体的对象，这样的类就是抽象类**。**抽象方法必须在抽象类中(也即是说抽象方法存在于一个类中，那么该类必须被声明为抽象类)，相对于接口来说抽象类中可以有普通方法**。抽象方法就如接口中声明的方法一样，只需要声明不需要实现，这也是由于**抽象类不能直接实例化**。且需要知道，**构造方法 和 static 方法不能是抽象的**。

​	

**相同**：① 都不能直接实例化，都可以被继承(接口可以继承接口、抽象类可以实现接口、抽象类可以继承实体类，但前提是实体类必须有明确的构造方法)

​			② 都是不断向上抽取的结果。



**不同**： ① 抽象类中可以有非抽象方法(普通方法等)，接口只能有抽象方法。

​			 ② 接口体现的是一种规范，抽象类体现的是模板式设计。(抽象类是对整个类整体进行抽象，包括属性、行为，但是接口却是对类局部(行为)进行抽象)

​			 ③ 在接口中，所有方法都是抽象的，其他语言如C++中的**多继承的特性可以通过 "多继承接口"来体现**。因而接口可以被多继承而抽象类只能被单继承。

​			④ 接口里不可以定义静态方法，抽象类可以有(但不能定义为 static abstract  方法，不被允许)

​			⑤ 接口没有构造方法，而抽象类需要有构造方法(即使没有声明，在编译过程编译器也会为抽象类添加默认的无参构造器)。



注意点：(1)**抽象类中不能有静态的抽象方法**，这是由于 **抽象类不能被实例化，也就是说JVM层面上它不被分配内存空间，而静态static修饰的方法在类进行实例化之前就已经被分配了内存**，这样就出现了矛盾：抽象类不被分配内存，而static修饰的方法必须别分配内存。

​				(2) **接口也不能有静态的抽象方法**，这是因为**接口中声明的方法是被public abstract隐性修饰**的，且接口也是无法直接实例化，导致不能被分配内存，故与static相悖。

​				(3) 为什么抽象类需要构造方法呢？这是因为继承了抽象类的子类的构造方法中会有super()调用父类抽象类的构造函数。(抽象类也是类的一种，被子类继承后，子类构造方法中就需要调用父类的构造方法)



#### 6.static关键字、final关键字的含义以及使用场景





#### 7.在子类的构造函数中为什么必须调用父类的构造函数



#### 8.了解过设计模式吗？说说你所熟悉的设计模式。





#### 9.Arrays.sort和Collections.sort 的实现原理和区别

​		这里的Collections是**一个工具类**，相比于**Collection接口**(这是一个接口，是List、Set、Deque所实现的接口，提供了对集合对象进行基本操作的通用接口方法)而言，首先Collections是一个工具类(类，而不是接口)，提供了一系列静态方法实现**对各种集合的搜索、排序、线程安全等操作，并且还有 混排(Shuffling)、反转(Reverse)、替换所有元素(fill)、拷贝(copy)、返回Collections中最小元素/最大元素(min/max)、返回指定源列表中最后一次出现指定目标列表的起始位置(lastIndexOfSubList)、返回指定源列表中第一次出现指定目标列表的起始位置(IndexOfSubList)、根据指定的距离循环移动指定列表中的元素(Rotate)**。

​		回到问题本身，Collections.sort方法底层实现原理是调用了Arrays.sort方法。接下来请看Collections中的sort方法的源代码：

```java
public static <T extends Comparable<? super T>> void sort(List<T> list) {
        list.sort(null);
    }

public static <T> void sort(List<T> list, Comparator<? super T> c) {
        list.sort(c);
    }
```

由上述可发现，均调用的是List集合中的sort方法，而List集合中的sort方法如下：

```java
default void sort(Comparator<? super E> c) {
        Object[] a = this.toArray();
        Arrays.sort(a, (Comparator) c);
        ListIterator<E> i = this.listIterator();
        for (Object e : a) {
            i.next();
            i.set((E) e);
        }
    }
```

可以看到，调用的是Arrays.sort方法。

​		那么，接下来该了解Arrays.sort的底层实现原理了，先看源代码：

```java
public static <T> void sort(T[] a, Comparator<? super T> c) {
        if (c == null) {
            sort(a);
        } else {
            if (LegacyMergeSort.userRequested)
                legacyMergeSort(a, c);
            else
                TimSort.sort(a, 0, a.length, c, null, 0, 0);
        }
    }

public static void sort(Object[] a) {
        if (LegacyMergeSort.userRequested)
            legacyMergeSort(a);
        else
            ComparableTimSort.sort(a, 0, a.length, null, 0, 0);
    }
```

​		这里，首先判断有没有传入比较器Comparator实例，若没有则进入sort(Object[] a)方法之中，并且要么采用 legacyMergeSort(a)归并排序，要么ComparableTimSort.sort (TimSort排序)。

​		TimSort排序：结合了归并排序(merge sort) 和插入排序(insertion sort) 而得出的排序算法。

```java
TimSort 算法为了减少对升序部分的回溯和对降序部分的性能倒退，将输入按其升序和降序特点进行了分区。排序的输入的单位不是一个个单独的数字，而是一个个的块-分区。其中每一个分区叫一个run。针对这些 run 序列，每次拿一个 run 出来按规则进行合并。每次合并会将两个 run合并成一个 run。合并的结果保存到栈中。合并直到消耗掉所有的 run，这时将栈上剩余的 run合并到只剩一个 run 为止。这时这个仅剩的run 便是排好序的结果。
```

Timsort算法的过程包括 :

（1）如何数组长度小于某个值，直接用二分插入排序算法 

（2）找到各个run，并入栈

 （3）按规则合并run





#### 10.如何区分IO密集型任务和CPU密集型任务

​		一般来说，如**文件读写、DB读写、网络请求等诸如此类为IO密集型任务**。而CPU密集型任务有：**计算型代码、Bitmap转换、Gson转换等**。

​		除此之外，还可以通过“**代码**”来进行划分。接下来将了解几个划分任务的重要指标。

​		① **wallTime**：任务的整体运行时长（包括了running + runnable + sleep等所有时长）

获取wallTime的代码：

```java
run() {
    long start = System.currentTimeMillis();
    // 业务代码
    long wallTime = System.currentTimeMillis() - start;
}
```



​		② **CPUTime**: cputime是任务真正在cpu上跑的时长，即为running时长

​		获取CPUTime的代码：

```java
run() {
    long start = SystemClock.currentThreadTimeMillis();
    // 业务代码
    long cpuTime = SystemClock.currentThreadTimeMillis() - start;
}
```

​		③ **IO Wait Time/Count**：指线程的iowait耗时。

获取IO Wait Time/Count的代码：

```java
/proc/pid/task/tid/sched    //相对位置
se.statistics.iowait_sum IO等待累计时间
se.statistics.iowait_count IO等待累计次数
```

​		④ **runnable time**：线程runnabel被调度的时长。

```java
/proc/pid/task/tid/sched
se.statistics.wait_sum 就绪队列等待累计时间
```



​		⑤ **Sleep Time**：线程阻塞时长（包括Interruptible-sleep和Uninterruptible-sleep和iowait的时长）

```java
/proc/pid/task/tid/sched
se.statistics.sum_sleep_runtime 阻塞累计时间
```

​		⑥ **utime/stime**：utime是线程在用户态运行时长，stime是线程在内核态运行时长

```java
/proc/pid/task/tid/stat
第14个字段是utime，第15个字段是stime
```

​		⑦ **rchar/wchar**：wchar是write和pwrite函数写入的byte数

```java
/proc/pid/task/tid/io
rchar: ...
wchar: ...
```

​		⑧ page_fault：缺页中断次数，分为major/minor fault。

```java
/proc/pid/task/tid/stat
第10个字段是minor_fault，第12个字段是major_fault
```

​		⑨ **ctx_switches**：线程在用户/内核态的切换次数，分为voluntary和involuntary两种切换

```java
/proc/pid/task/tid/sched
nr_switches 总共切换次数
nr_voluntary_switches 自愿切换次数
nr_involuntary_switches 非自愿切换次数
```

​		⑩ **percpuload**：平均每个cpu的执行时长

```java
/proc/pid/task/tid/sched
avg_per_cpu
```



通过这些指标，就可以开始任务型的确定了。



如IO型任务，如下代码：

```java
val br = BufferedReader(FileReader("xxxx"), 1024)
try {
    while (br.readLine() != null) {}
} finally {
    if (br != null) {
        br.close()
    }
}
```

基于上述**部分3. iowait time/count**，我们可以在对应的日志文件中看出这段代码有明显的**iowait**。



如CPU密集型任务，如下代码：

```java
var n = 0.0
for (i in 0..9999999) {
    n = Math.cos(i.toDouble())
}
```

基于上述**部分6. utime/stime**的内容，看一看出这段代码utime会占比非常高，且几乎没有stime，此外没有io相关的耗时。



对于业务开发来说：

​		为了**不占用主线程** -> 所以**开启一个新线程** -> **频繁的new线程又会带来大量的开销** -> 所以**使用线程池进行复用** -> 而**不合理的线程池设计又会带来线程使用低效，甚至新加入的任务只能等待** -> **优化线程池**

​		**区别任务是IO型还是CPU型，能为线程池的设计提供更好的指导思想，提升线程运行效率，降低业务上的不必要等待。**



基于上述，使用java代码来展示出  **判断任务类型的核心思路**：

```java
class TaskInfo {
    var cpuTimeStamp = 0.0
    var timeStamp = 0.0
    var iowaitTime = 0.0
    var sleepTime = 0.0
    var runnableTime = 0.0
    var totalSwitches = 0.0
    var voluntarySwitches = 0.0
}
```

```java
object TaskInfoUtils {
    private const val SUM_SLEEP_RUNTIME = "se.statistics.sum_sleep_runtime"
    private const val WAIT_SUM = "se.statistics.wait_sum"
    private const val IOWAIT_SUM = "se.statistics.iowait_sum"
    private const val NR_SWITCHES = "nr_switches "
    private const val NR_VOLUNTARY_SWITCHES = "nr_voluntary_switches"
    private var schedPath = ThreadLocal<String>()
    fun buildCurTaskInfo(): TaskInfo {
        val threadInfo = TaskInfo()
        threadInfo.timeStamp = System.currentTimeMillis().toDouble()
        threadInfo.cpuTimeStamp = SystemClock.currentThreadTimeMillis().toDouble()
        if (schedPath.get() == null) {
            schedPath.set("/proc/${android.os.Process.myPid()}/task/${getTid()}/sched")
        }
        BufferedReader(FileReader(schedPath.get()), READ_BUFFER_SIZE).use { br ->
            br.readLines().forEach { line ->
                when {
                    line.startsWith(SUM_SLEEP_RUNTIME) -> threadInfo.sleepTime = line.split(":")[1].toDouble()
                    line.startsWith(WAIT_SUM) -> threadInfo.runnableTime = line.split(":")[1].toDouble()
                    line.startsWith(IOWAIT_SUM) -> threadInfo.iowaitTime = line.split(":")[1].toDouble()
                    line.startsWith(NR_SWITCHES) -> threadInfo.totalSwitches = line.split(":")[1].toDouble()
                    line.startsWith(NR_VOLUNTARY_SWITCHES) -> threadInfo.voluntarySwitches = line.split(":")[1].toDouble()
                }
            }
        }
        return threadInfo
    }
}
```

```java
object TaskBoundJudge {
    private const val CPU_CPUTIME_INTERVAL = 0.8
    private const val CPU_SWITCHES_INTERVAL = 0.1
    private const val CPU_IOWAIT_INTERVAL = 0.01
    private const val CPU_SLEEP_INTERVAL = 0.02
    private const val CPU_CPUTIME_WEIGHTS = 0.1
    private const val CPU_SWITCHES_WEIGHTS = 0.35
    private const val CPU_IOWAIT_WEIGHTS = 0.15
    private const val CPU_SLEEP_WEIGHTS = 0.40
    private const val IO_CPUTIME_INTERVAL = 0.5
    private const val IO_SWITCHES_INTERVAL = 0.4
    private const val IO_IOWAIT_INTERVAL = 0.1
    private const val IO_SLEEP_INTERVAL = 0.15
    private const val IO_CPUTIME_WEIGHTS = 0.1
    private const val IO_SWITCHES_WEIGHTS = 0.35
    private const val IO_IOWAIT_WEIGHTS = 0.35
    private const val IO_SLEEP_WEIGHTS = 0.2
    fun isCpuTask(start: TaskInfo?, end: TaskInfo?): Boolean {
        if (start == null || end == null) {
            return false
        }
        val wallTime  = end.timeStamp - start.timeStamp
        val cpuTime = end.cpuTimeStamp - start.cpuTimeStamp
        val runnableTime = end.runnableTime - start.runnableTime
        val totalSwitches = end.totalSwitches - start.totalSwitches
        val voluntarySwitches = end.voluntarySwitches - start.voluntarySwitches
        val iowaitTime = end.iowaitTime - start.iowaitTime
        val sleepTime = end.sleepTime - start.sleepTime
        var result = 0.0
        if (cpuTime / (wallTime - runnableTime) > CPU_CPUTIME_INTERVAL) {
            result += CPU_CPUTIME_WEIGHTS
        }
        if (voluntarySwitches / totalSwitches < CPU_SWITCHES_INTERVAL) {
            result += CPU_SWITCHES_WEIGHTS
        }
        if (iowaitTime / sleepTime < CPU_IOWAIT_INTERVAL) {
            result += CPU_IOWAIT_WEIGHTS
        }
        if (sleepTime / (wallTime - runnableTime) < CPU_SLEEP_INTERVAL) {
            result += CPU_SLEEP_WEIGHTS
        }
        return result > 0.5
    }
    fun isIOTask(start: TaskInfo?, end: TaskInfo?): Boolean {
        if (start == null || end == null) {
            return false
        }
        val wallTime = end.timeStamp - start.timeStamp
        val cpuTime = end.cpuTimeStamp - start.cpuTimeStamp
        val runnableTime = end.runnableTime - start.runnableTime
        val totalSwitches = end.totalSwitches - start.totalSwitches
        val voluntarySwitches = end.voluntarySwitches - start.voluntarySwitches
        val iowaitTime = end.iowaitTime - start.iowaitTime
        val sleepTime = end.sleepTime - start.sleepTime
        var result = 0.0
        if (cpuTime / (wallTime - runnableTime) < IO_CPUTIME_INTERVAL) {
            result += IO_CPUTIME_WEIGHTS
        }
        if (voluntarySwitches / totalSwitches > IO_SWITCHES_INTERVAL) {
            result += IO_SWITCHES_WEIGHTS
        }
        if (iowaitTime / sleepTime > IO_IOWAIT_INTERVAL) {
            result += IO_IOWAIT_WEIGHTS
        }
        if (sleepTime / (wallTime - runnableTime) > IO_SLEEP_INTERVAL) {
            result += IO_SLEEP_WEIGHTS
        }
        return result > 0.5
    }
}
```

当我们想对某个方法进行计算是CPU还是IO。可以在这个方法的开始、结束调用 `TaskInfoUtils.buildCurTaskInfo()`；然后调用 `TaskBoundJudge.isCpuTask(start,end)`，`TaskBoundJudge.isIOTask(start,end)`即可。



基于IO密集型任务的线程池：

```java
public static final ExecutorService IO_EXECUTOR = new ThreadPoolExecutor(
    2, 
    128, 
    15, 
    TimeUnit.SECONDS, 
    new SynchronousQueue<>(), 
    new CustomThreadFactory("MDove-IO", CustomThreadPriority.NORMAL),
    AbortPolicy() // 根据业务情况，自行定义拒绝实现。比如上报监控平台
);
```

CPU密集型参考线程池：

```java
public static final int CPU_COUNT = Runtime.getRuntime().availableProcessors();
public static final int MAXIMUM_POOL_SIZE = CPU_COUNT * 2 + 1;
private static final int CPU_CORE_POOL_SIZE = Math.max(Math.min(MAXIMUM_POOL_SIZE, 4), Math.min(CPU_COUNT + 1, 9));
public static final ExecutorService CPU_EXECUTOR = new ThreadPoolExecutor(
    CPU_CORE_POOL_SIZE,
    CPU_COUNT * 2 + 1,
    30, 
    TimeUnit.SECONDS,
    new LinkedBlockingQueue<>(256),
    new SSThreadFactory("MDove-CPU", CustomThreadPriority.NORMAL),
    AbortPolicy() // 根据业务情况，自行定义拒绝实现。比如上报监控平台
);
```

上述线程池设计的额外代码：

```java
class CustomThreadFactory : ThreadFactory {
    var name: String
        private set
    private var priority = CustomThreadPriority.NORMAL
    constructor(name: String, priority: CustomThreadPriority) {
        this.name = name
        this.priority = priority
    }
    override fun newThread(r: Runnable): Thread {
        val name = name + "-" + sCount.incrementAndGet()
        return object : Thread(r, name) {
            override fun run() {
                if (priority == CustomThreadPriority.LOW) {
                    Process.setThreadPriority(Process.THREAD_PRIORITY_BACKGROUND)
                } else if (priority == CustomThreadPriority.HIGH) {
                    Process.setThreadPriority(Process.THREAD_PRIORITY_DISPLAY)
                }
                super.run()
            }
        }
    }
    companion object {
        private val sCount = AtomicInteger(0)
    }
}
enum class CustomThreadPriority {
    LOW, NORMAL, HIGH, IMMEDIATE
}
```







------

## 计算机网络：

#### 	1.计算机网络内容：TCP三次握手的概念，为什么不能两次握手？ (按书中的知识讲的，但面试官觉得繁琐，说一句话"根据初始序列号"什么就行了)









#### 	2.（笔试） TCP三次握手以及TCP四次挥手









#### 3.get和post区别

​	GET 和POST都是HTTP的请求方法。

​	那么，HTTP请求报文的格式怎么样呢？具体看下图：

![HTTP报文](C:\Users\AWU\Desktop\面试学习\面经问题图片存储池\HTTP报文.png)



可以看到请求报文由三部分组成：

​		请求行：由请求方法（Method）、URL 字段和 HTTP 的协议版本组成，注意其中的空格、回车符和换行符均不可省略，所以我们的请求方法实际上就是位于请求行中的了。

​		请求头部：位于请求行之后，个数可以为 0~若干个，每个请求头部都包含一个头部字段名和一个值，它们之间用冒号 ":" 分隔，在最后用回车符和换行符表示结束。
​		请求数据：如果请求方法为 GET，那么请求数据为空。它主要是在 POST 中进行使用，适用于需要填表单（FORM）的场景。



回到GET和POST方法中，关于GET方法：

​	① GET方法请求的数据会附在 URL 之后（放在请求行中），以 **?** 分割 URL 和传输数据，**多个参数用 & 连接**。

​	② 根据HTTP规范，GET用于信息获取，而且应是 **安全和幂等**。( **安全**，指的是非修改信息，即该操作用于获取信息而非修改信息。也就是说**GET方法仅仅是获取资源信息，就如数据库查询操作一样。**

​	**幂等**，指的是对**同一URL的多个请求应该返回同样的结果**。   而在实际过程中，这个规定没有那么严格。例如在一个新闻应用中，新闻站点的头版不断更新，虽然第二次请求会返回不同的一批新闻，该操作仍然被认为是安全的和幂等的，因为它**总是返回当前的新闻**。)

​	③ GET会被浏览器主动缓存，如果下次传输数据相同，那么就会返回缓存中的内容，以便更快的展示数据。

​	④ GET 方法的 URL **一般都具有长度限制**，但是需要注意的是 **HTTP 协议中并未规定 GET 请求的长度。这个长度限制主要是由浏览器和 Web 服务器所决定的，并且各个浏览器对长度的限制也各不相同**。 

​	⑤ GET方法**只产生一个TCP数据包**，浏览器会把请求头和请求数据捆绑发送出去，服务器响应200即返回数据。

​	⑥ POST的安全性要比GET的安全性高。

有关POST：

​	① 根据HTTP规范，**POST表示可能修改服务器上的资源的请求**。

​	② POST方法因为**可能修改服务器上的资源**，所以**不符合安全和幂等性**。

​	③ POST方法的请求信息是放在请求数据中，所以它的**请求信息是没有长度限制**的。

​	④ **POST方法会产生两个TCP数据包**，浏览器会先将请求头发送给服务器，待服务器响应100 continue(接收正常，允许继续发送) ，浏览器再发送请求数据，服务器响应200返回数据。



​		GET和POST的区别呢？上面所述只是各自的特点(特性)，看起来似乎有些许不同，但它们的本质是一样的。**都是HTTP协议的请求方法。而HTTP又基于TCP/IP协议进行的数据传输**，所以**实际上GET和POST都是TCP连接,并无区别。但是由于 HTTP 的规定以及浏览器/服务器的限制，导致它们在应用过程中可能会有所不同**

​		即使GET和POST的底层是TCP，在HTTP协议中仍需要为数据传输进行一个分类——这一点可以理解成，假如直接使用TCP进行数据传输，那么无论是获取资源还是修改资源的请求均为TCP连接， 并无法判断出是什么类型的请求。所以在HTTP协议中，就会对不同的请求设置不同的类别从而方便管理和辨别。





#### 4.Cookie和Session的区别

​	首先，需要了解为什么需要Cookie和Session呢？这是因为HTTP协议是一个无状态的协议，不会保存客户端的状态。

​	cookie的出现解决了上面的问题，第一次登陆后服务器会返回一个cookie给浏览器，然后(客户端)浏览器保存在本地中，当用户第二次返回请求时，就会把上次请求存储的cookie数据自动携带给服务器。

​	如果**关闭浏览器cookie即刻失效**——说明cookie保存在**内存**中；若**不失效**则是在**磁盘**中。















------

## JUC（多线程与并发）：

#### 	1.线程池的概念(https://blog.csdn.net/qq_44750696/article/details/104640143)

​	**什么是线程池？**——一系列线程的集合，称为线程池。

​	**使用线程池有什么好处呢**？——① 降低资源消耗。通过重复利用已创建的线程，来避免了线程的创建和销毁所造成的资源消耗。

​														  ② 提高响应速度。使用已创建的线程，可以立即执行任务。

​														  ③ 提高线程的可管理性。如果无限制地创建线程，在高并发情况下，不仅会消耗系统资源，还会降低系统稳定性。使用线程池可以对多个线程请求进行 **统一分配、调优和监控**。提高了对线程的可管理性。

​	

​	**线程池的工作机制？**—— 在线程池的编程模式下，系统将任务传给线程池，让线程池根据当前**核心线程数、阻塞队列、最大线程数是否已满**，逐级向下查找，若都已满则实行 **拒绝策略**。且线程池中，仍旧是一个线程只能执行一个任务，但是可以向线程池提交多个任务来实现多线程。

​	

​	**那么有哪些线程池呢？**——  首先，可以通过 **java.util.concurrent包下的 Executors 类** 提供一系列**静态工厂方法**，进行各种**线程池的创建**。

​			常用的方法如下：

```java
public static ExecutorService newFixedThreadPool()
public static ExecutorService newSingleThreadExecutor()
public static ExecutorService newCachedThreadPool()
public static ScheduledExecutorService newSingleThreadScheduledExecutor()
public static ScheduledExecutorService newScheduledThreadPool()
    1、newFixedThreadPool：固定数量的线程池，该方法返回一个 可重用的、`固定线程数量`的线程池；

　　2、newSingleThreadExecutor：单线程的线程池，它只会用`唯一的线程`来执行任务，保证所有任务按照`指定顺序(FIFO(先进先出),  LIFO(后进先出),  优先级)`执行；

　　3、newCachedThreadPool：`可缓存线程池`，该线程池可以根据实际情况`调整池子中的线程数量`，当执行当前任务时，上一个任务已经完成，会复用执行上一个任务的线程，而不用每次新建线程，如果上一个线程没有结束才会新建线程，可缓存型池子通常用于执行一些生存期较短的任务；

　　4、newScheduledThreadPool：`可定时线程池`，该线程池可以设定线程的执行时间，可以用来去执行一些`定时及周期性`的任务。

```

通过上述，再深入了解一些。

```java
public static ExecutorService newFixedThreadPool(int nThreads) {
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>());
    }
```

通过代码可以看到，该静态工厂方法在创建线程池时，实质上调用的是 **ThreadPoolExecutor** **类**来进行线程池的创建。									



​	那么**线程池是如何实现线程复用的**呢？—— 首先，需要了解线程的实现方式：①通过extends**继承Thread类**，并**重写run()**方法。  ②通过 implement **实现 Callable或Runnable 接口，并重写run()** 方法。



​		在这里，我们知道线程有五种状态：**新建、就绪、运行、阻塞、终止**。

​		而一般一个线程在执行完任务后就结束了，如何让它再执行下一个任务呢？想要实现线程的复用，那么**必须从Runnable接口的run()方法上入手**。

​		接下来，通过查看ThreadPoolExecutor线程池类源码可知：

```java
// 内部类 Worker
private final class Worker extends AbstractQueuedSynchronizer implements Runnable
         {
             /** 各种代码...  */        
             Runnable firstTask;       
             Worker(Runnable firstTask) {
                 setState(-1); // inhibit interrupts until runWorker
                 this.firstTask = firstTask;
                 this.thread = getThreadFactory().newThread(this);
             }       
             public void run() {
                 runWorker(this);
             }        
         }



     //addWorker()方法，启动线程； 
     private boolean addWorker(Runnable firstTask, boolean core) {
       w = new Worker(firstTask);
       final Thread t = w.thread;
       //...代码
       
       // 很明显了，从这里启动线程的； 
       t.start(); 
       ...//代码
     }



     // getTask()方法，很显然这个方法是从 任务队列(workQueue)中，获取任务； 
      private Runnable getTask() {
                 // 各种代码...
                 if ((wc > maximumPoolSize || (timed && timedOut))
                     && (wc > 1 || workQueue.isEmpty())) {
                     //...
                 } // ...    
         }



     // 核心部分：runWorker()方法：
         final void runWorker(Worker w) {
              // 各种代码...
             Runnable task = w.firstTask;
             w.firstTask = null;
             // 各种代码...
             try {
             // 重点：看这个大while循环：实现的线程复用；  
                 while (task != null || (task = getTask()) != null) {
                      // 各种代码...
                 }
             }
         }

```

从上面的学习中，我们知道，线程池是通过 new ThreadPoolExecutor得到的，而**线程则是通过其内部类Worker创建**，也就是说，只要 **new Worker(Runnable firstTask)，就会创建一个线程**，因为Worker的构造方法里边有这么一句：

```java
`this.thread = getThreadFactory().newThread(this);`
```

 并且创建线程的时候，会将**这个内部类本身this** 传到参数列表里边，去当task。

​		在线程池中，线程是**如何启动的**：在源码的addWorker()方法中，可以看到：`t.start();` 很明显了，从**addWorker()方法**这里**启动线程**的；

​		那么，启动了线程，**线程又是如何运行的**呢？——从源码的addWorker()方法中有:

```java
w = new Worker(firstTask);
```

也就是说，在线程启动的时候已经将内部类worker对象传入进去了，而内部类Worker实现了Runnable接口并重写了run()方法。这意味着：**jvm会执行Worker里的run方法，使线程进入运行状态；**



那么，**线程池是如何实现了复用的呢**？—— **用Work内部类中的run()方法里边的runWorker()方法里边的while大循环，实现了线程的复用；**

```java
final void runWorker(Worker w) {   // 各种代码...
  // 核心：这个大while循环：
     while (task != null || (task = getTask()) != null) {
          // 各种代码...
     }
     // 各种代码...
}

```

从源码可看出,这个runWorker()方法里面，有一个大大的**while循环，**

① **当我们的task任务，不为空的时候，即，通过getTask()方法，可以一直获取到新的任务 ，那么这个while循环就永远在进行；**
 从而runWorker()方法不会停止，runWorker()方法外边的run()方法也就不会停止，继而**线程会一直处于运行状态，去执行新的任务，从而达到了线程复用的目的**；

② 当我们的**task任务为空了，则while循环结束，也就是说，这个线程结束** 。








#### 补充点：Callable和Runnable接口的区别有什么呢

​	相同：
​		① 两个都属于接口。

​		② 都需要调用Thread类中的start()方法启动线程

​	不同： 

​		① Callable接口的核心是call()方法，允许返回值。Runnable接口的核心是run()方法，没有返回值

​		②call()方法可以抛出异常，run方法不能抛出异常。(这是因为Runnable接口是jdk1.1版本就有了，当时并并不存在返回值，后期jdk1.5版本进行优化，出现了Callable接口实现返回值和抛异常)

​		③ Callable和Runnable接口都可以应用于 Executors类中，但Thread类只支持Runnable.( 使用Callable接口来实现线程的创建，需要借助 Future接口的唯一实现类FutureTask类获取返回结果，而FutureTask里间接实现了Runnable接口属于Runnable的子类，故通过创建获得了Callable接口实现类的FutureTask类作为Thread类的start()方法的参数)																		





#### 	2.线程安全下的单例模式？(https://blog.csdn.net/cselmu9/article/details/51366946)

​	首先，需要了解什么是单例模式？——《Head First 设计模式》一书中，对单例模式的简要定义为：确保一个类只有一个实例，并提供一个全局访问点。



那么，单例模式有**哪些实现方式呢**？

① **饿汉式单例模式**——使用static关键字静态初始化时创建单例对象。在调用方法时使用此创建好了的单例对象即可。

```java
public class MySingleton {
	
	private static MySingleton instance = new MySingleton();  //在静态初始化时创建该单例对象
	
	private MySingleton(){}
	
	public static MySingleton getInstance() {
		return instance;
	}
	
}
```

② 懒汉式单例模式——在调用方法时获取实例对象时才创建单例对象。但该操作在多线程并发下，无法保证单例对象是否唯一。

```java

public class MySingleton {
	
	private static MySingleton instance = null;
	
	private MySingleton(){}
	
	public static MySingleton getInstance() {
		if(instance == null){//懒汉式
			instance = new MySingleton();
		}
		return instance;
	}
}

```

③线程安全的懒汉式单例模式( 方法中声明synchronized关键字、同步代码块实现、 针对某些重要的代码来进行单独的同步（可能非线程安全） )

​		(1) 方法中声明synchronized关键字：出现线程非安全问题，这是由于多个线程进入getInstance()方法，故对此方法进行sychronized 的锁同步机制。但该方法的运行效率会很低。

```java
public class MySingleton {
	
	private static MySingleton instance = null;
	
	private MySingleton(){}
	
	public synchronized static MySingleton getInstance() {
		try { 
			if(instance != null){//懒汉式 
				
			}else{
				//创建实例之前可能会有一些准备性的耗时工作 
				Thread.sleep(300);
				instance = new MySingleton();
			}
		} catch (InterruptedException e) { 
			e.printStackTrace();
		}
		return instance;
	}
} 
```

​	(2)  同步代码块实现：这样将会锁住MySingleton整个类，同样的效率也很低下。	

```java
public class MySingleton {
	
	private static MySingleton instance = null;
	
	private MySingleton(){}
	
	//public synchronized static MySingleton getInstance() {
	public static MySingleton getInstance() {
		try { 
			synchronized (MySingleton.class) {
				if(instance != null){//懒汉式 
					
				}else{
					//创建实例之前可能会有一些准备性的耗时工作 
					Thread.sleep(300);
					instance = new MySingleton();
				}
			}
		} catch (InterruptedException e) { 
			e.printStackTrace();
		}
		return instance;
	}
} 
```

​	(3) 针对某些重要的代码来进行单独的同步（可能非线程安全）: 针对某些重要的代码进行单独的同步，而不是全部进行同步，可以极大的提高执行效率

```java
public class MySingleton {
	
	private static MySingleton instance = null;
	
	private MySingleton(){}
	 
	public static MySingleton getInstance() {
		try {  
			if(instance != null){//懒汉式 
				
			}else{
				//创建实例之前可能会有一些准备性的耗时工作 
				Thread.sleep(300);
				synchronized (MySingleton.class) {
					instance = new MySingleton();
				}
			} 
		} catch (InterruptedException e) { 
			e.printStackTrace();
		}
		return instance;
	}
}
```



④ **双检查锁机制**：首先检查是否实例已经创建了，如果尚未创建，才进行同步。这样一来只有第一次会同步。

注意：在1.4及更早版本的Java中，许多 JVM 对于volatile关键字的实现会导致双重检查加锁的失效。

**且使用volatile关键字保其可见性、禁止指令重排的作用, 保证先初始化, 再把对象引用赋值给instance变量.** 

```java
public class MySingleton {
	
	//使用volatile关键字保其可见性、禁止指令重排的作用, 保证先初始化, 再把对象引用赋值给instance变量. 
	volatile private static MySingleton instance = null;
	
	private MySingleton(){}
	 
	public static MySingleton getInstance() {
		try {  
			if(instance != null){//懒汉式 
				
			}else{
				//创建实例之前可能会有一些准备性的耗时工作 
				//Thread.sleep(300);
				synchronized (MySingleton.class) {
					if(instance == null){//二次检查
						instance = new MySingleton();
					}
				}
			} 
		} catch (InterruptedException e) { 
			e.printStackTrace();
		}
		return instance;
	}
} 
```



#### 3.高并发和多线程的关系和区别?

首先，需要了解**高并发和多线程的定义**。

所谓**高并发，是一种系统运行过程中遇到的一种“短时间内遇到大量操作请求”的情况，主要发生在web系统集中大量访问收到大量请求**（例如：12306的抢票情况；天猫双十一活动）。该情况的发生会导致系统在这段时间内执行大量操作，例如对资源的请求、数据库的操作等（定义）

高并发相关**常用的一些指标有：响应时间、吞吐量、每秒查询率QPS、并发用户数**（**情景实践中的第一题**有关此类的叙述)

而多线程，指的是一个进程中可以有多个执行路径。













------

## JVM:

#### 	1.垃圾收集器的概念，判定垃圾对象的方法？有哪些垃圾收集器以及实现过程？









#### 2.双亲委派模型了解吗?



#### 3.数组在内存中如何分配







------

## 数据结构与算法：

#### 	1.有哪些排序算法不稳定以及稳定的？











------



## Redis分布式缓存数据库：

#### 1.Redis的数据存储格式？

​	答：redis自身是一个Map映射结构，其中所有数据都是采用 key:value (键值对) 的形式存储。

​			Redis的数据类型指的是存储的数据的类型，也就是 value 部分的类型，**key 部分永远都是字符串**







#### 	2.什么是跳表了解吗？





#### 	3.有关Redis的五大数据类型？缓存击穿、缓存穿透、缓存雪崩的概念以及防治措施

答：string 字符串（可以为整形、浮点型和字符串，统称为元素）
list 列表（实现队列,元素不唯一，先入先出原则）
set 集合（各不相同的元素）
hash hash散列值（hash的key必须是唯一的） hash类型下的value只能存储字符串，不允许存储其他类型数据，不存在嵌套现象。如果数据未获取到，对应的值为nil
sort set 有序集合



应用场景方面：

​	①String类型的应用场景：微信投票，每个微信号每4个小时只能投1票。电商商家开启热门商品推荐。新闻网站出现热点新闻。B站、微博、抖音等显示粉丝数和视频、微博等数量(这些是热点数据，在不断变化) 

​			 如何实现这些应用场景呢？—— 解决思路是：给用户设置一个唯一的id，并为其设置一个有效时长，当时间已经超过设定时间后将id删除。 这是利用了**setex**命令来实现 数据的**时效性（控制数据的生命周期，实现热点数据）**。而对于粉丝数和视频数这类的，可以通过 在Redis中为用户设定用户信息，以用户主键和属性值作为key，后台设定时间定时刷新数据即可。

​	②hash类型应用场景：购物车





------



## MYSQL:

### 	1.sql语句的执行顺序了解吗？  （https://blog.csdn.net/u014044812/article/details/51004754）

​			① from  ② join   ③ on   ④ where  ⑤ group by  ⑥ avg,sum...  ⑦  having  ⑧ select  ⑨ distinct  ⑩ order by  (11).limit

​		具体流程：

```
第一步：首先对from子句中的前两个表执行一个笛卡尔乘积，此时生成虚拟表 vt1（选择相对小的表做基础表）。 
第二步：接下来便是应用on筛选器，on 中的逻辑表达式将应用到 vt1 中的各个行，筛选出满足on逻辑表达式的行，生成虚拟表 vt2 。
第三步：如果是outer join 那么这一步就将添加外部行，left outer jion 就把左表在第二步中过滤的添加进来，如果是right outer join 那么就将右表在第二步中过滤掉的行添加进来，这样生成虚拟表 vt3 。

第四步：如果 from 子句中的表数目多余两个表，那么就将vt3和第三个表连接从而计算笛卡尔乘积，生成虚拟表，该过程就是一个重复1-3的步骤，最终得到一个新的虚拟表 vt3。 
第五步：应用where筛选器，对上一步生产的虚拟表引用where筛选器，生成虚拟表vt4，在这有个比较重要的细节不得不说一下，对于包含outer join子句的查询，就有一个让人感到困惑的问题，到底在on筛选器还是用where筛选器指定逻辑表达式呢？on和where的最大区别在于，如果在on应用逻辑表达式那么在第三步outer join中还可以把移除的行再次添加回来，而where的移除的最终的。举个简单的例子，有一个学生表（班级,姓名）和一个成绩表(姓名,成绩)，我现在需要返回一个x班级的全体同学的成绩，但是这个班级有几个学生缺考，也就是说在成绩表中没有记录。为了得到我们预期的结果我们就需要在on子句指定学生和成绩表的关系（学生.姓名=成绩.姓名）那么我们是否发现在执行第二步的时候，对于没有参加考试的学生记录就不会出现在vt2中，因为他们被on的逻辑表达式过滤掉了,但是我们用left outer join就可以把左表（学生）中没有参加考试的学生找回来，因为我们想返回的是x班级的所有学生，如果在on中应用学生.班级='x'的话，left outer join会把x班级的所有学生记录找回（感谢网友康钦谋__康钦苗的指正），所以只能在where筛选器中应用学生.班级='x' 因为它的过滤是最终的。 

第六步：group by 子句将中的唯一的值组合成为一组，得到虚拟表vt5。如果应用了group by，那么后面的所有步骤都只能得到的vt5的列或者是聚合函数（count、sum、avg等）。原因在于最终的结果集中只为每个组包含一行。这一点请牢记。 

第七步：应用cube或者rollup选项，为vt5生成超组，生成vt6. 
第八步：应用having筛选器，生成vt7。having筛选器是第一个也是为唯一一个应用到已分组数据的筛选器。 
第九步：处理select子句。将vt7中的在select中出现的列筛选出来。生成vt8. 

第十步：应用distinct子句，vt8中移除相同的行，生成vt9。事实上如果应用了group by子句那么distinct是多余的，原因同样在于，分组的时候是将列中唯一的值分成一组，同时只为每一组返回一行记录，那么所以的记录都将是不相同的。 

第十一步：应用order by子句。按照order_by_condition排序vt9，此时返回的一个游标，而不是虚拟表。sql是基于集合的理论的，集合不会预先对他的行排序，它只是成员的逻辑集合，成员的顺序是无关紧要的。对表进行排序的查询可以返回一个对象，这个对象包含特定的物理顺序的逻辑组织。这个对象就叫游标。正因为返回值是游标，那么使用order by 子句查询不能应用于表表达式。排序是很需要成本的，除非你必须要排序，否则最好不要指定order by，最后，在这一步中是第一个也是唯一一个可以使用select列表中别名的步骤。 

第十二步：应用top选项。此时才返回结果给请求者即用户。 
 
```



### 2.mysql的内置函数有哪些？





### 3.mysql中count(*)和count(1)和count(column)区别



解决问题地址：https://liuchenyang0515.blog.csdn.net/article/details/120851980?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.essearch_pc_relevant&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.essearch_pc_relevant

```java
1.count() 统计满足查询条件的结果集的总行数(包含null)，其中count(1)和count()的处理逻辑完全相同
2.count(column) 如果列定义时不允许为null，那么统计满足查询条件的不为null的总行数
```

在解决该问题时，了解以下：

​		聚集索引和非聚集索引中的记录是一一对应的，而非聚集索引记录中包含的列（索引列+主键`id`）是少于聚集索引（所有列）记录的，所以同样数量的非聚集索引记录比聚集索引记录占用更少的存储空间。

​		当统计表中有多少数据时，会常常使用如下语句：

```java
SELECT COUNT(*) FROM demo_info;
```

分析一下执行计划：

![MYSQL中的selectcount()](C:\Users\AWU\Desktop\面试学习\面经问题图片存储池\MYSQL中的selectcount().png)

```java
在执行上述查询时，server层会维护一个名叫count的变量，然后：

server层向InnoDB要第一条记录。

InnoDB找到uk_key2的第一条二级索引记录，并返回给server层（注意：由于此时只是统计记录数量，所以并不需要回表）。

由于count函数的参数是*，MySQL会将*当作常数0处理。由于0并不是NULL，server层给count变量加1。

server层向InnoDB要下一条记录。

InnoDB通过二级索引记录的next_record属性找到下一条二级索引记录，并返回给server层。

server层继续给count变量加1。

重复上述过程，直到InnoDB向server层返回没记录可查的消息。

server层将最终的count变量的值发送到客户端。
 
```



​		对于**count(*)、count(1)或者任意的count(常数) 来说，**读取哪个索引的记录并不重要，因为**server层只关心存储引擎是否读取到了记录**，而**并不需要从记录中提取指定的字段来判断是否为NULL**。所以**优化器会使用占用存储空间最小的那个索引来执行查询**。



```
explain SELECT COUNT(id) FROM demo_info;
```

下面来看看对于主键id的查询，而对于**count(id)**来说，由于**id是主键**，**不论是聚簇索引记录，还是任意一个二级索引记录中都会包含主键字段**，所以读取任意一个索引中的记录都可以获取到id字段，此时**优化器也会选择占用存储空间最小的那个索引来执行查询**。

![Mysql的count(id主键)](C:\Users\AWU\Desktop\面试学习\面经问题图片存储池\Mysql的count(id主键).png)



```
explain select count(common_field) from demo_info
```

​		再来看看非索引列，对于**count(非索引列)**来说，优化器选择全盘扫描，这说明**只能在聚集索引的叶子结点顺序扫描**。

![Mysql中的count(非索引列)](C:\Users\AWU\Desktop\面试学习\面经问题图片存储池\Mysql中的count(非索引列).png)

> 请确认你理解了全表扫描，它是顺序扫描聚集索引的所有叶子结点并判断。



**什么是全盘扫描？**





综上所述：

```java
对于count(*)、count(常数)、count(主键)形式的count函数来说，优化器可以选择扫描成本最小的索引执行查询，从而提升效率，它们的执行过程是一样的，只不过在判断表达式是否为NULL时选择不同的判断方式，这个判断为NULL的过程的代价可以忽略不计，所以我们可以认为count(*)、count(常数)、count(主键)所需要的代价是相同的。

  而对于count(非索引列)来说，优化器选择全表扫描，说明只能在聚集索引的叶子结点顺序扫描。

  count(二级索引列)只能选择包含我们指定的列的索引去执行查询，可能导致优化器选择的索引执行的代价并不是最小。

  其实上述这些区别就是因为非聚集索引记录比聚集索引记录占用更少的存储空间，减少更多I/O成本，所以优化器才有了不同索引的选择，仅此而已。
 
```





















------



## 情景实践：

### 	1.如何实现一个高并发高可用系统：https://blog.csdn.net/u014352080/article/details/81487303

​		首先，需要知道什么是高并发和高可用：

​		**高并发（High Concurrency）是一种系统运行过程中遇到的一种“短时间内遇到大量操作请求”的情况，主要发生在web系统集中大量访问收到大量请求（例如：12306的抢票情况；天猫双十一活动）。该情况的发生会导致系统在这段时间内执行大量操作，例如对资源的请求，数据库的操作**等。

高并发相关常用的**处理指标**有：

​	1.**响应时间**(Response Time): 系统对请求做出的响应时间。

​	2.**吞吐量**(Throughput) ：单位时间内处理请求的数量。

​	3.**每秒查询率QPS**( Query Per Second ): QPS：每秒响应请求数。

​	4.**并发用户数**：同时承载正常使用系统功能的用户数量。



​	高可用HA（High Availability）是分布式系统架构设计中必须考虑的因素之一，它通常是指，通过**设计减少系统不能提供服务的时间**。

那么要**如何保障高并发和高可用呢**？ 

​	首先，互联网分布式架构设计，提供系统**并发能力**的方式理论上有两种：**垂直扩展和水平扩展**  (这里是指保障系统的高并发)

垂直扩展：指的是**提高单机处理能力**。垂直扩展的方式有两种——

​		(1) 增强**单机硬件性能**。例如：增加CPU核数如32核，升级更好的网卡如万兆，升级更好的硬盘如SSD，扩充硬盘容量如2T，扩充系统内存如128G；

​		(2) 提升**单机架构性能**，例如：使用Cache来减少IO次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间；

由于一台机器的单机性能始终会有极限，所以**互联网分布式架构设计高并发的解决方案实际上**还是要**通过水平扩展解决**。

水平扩展：指的是**增加服务器数量，线性扩充系统性能**。  (水平扩展对系统架构设计是有要求的，如何在架构各层进行可水平扩展的设计，以及互联网公司架构各层常见的水平扩展实践)



其次，如何保障高可用？   —— 在系统设计的过程中避免单点( 单点是系统高可用的大敌 ，什么是单点呢)，理论上说，高可用保证的原则是 **集群化**，或者叫 **冗余**，即 只有一个单点服务，挂了服务会受影响，如果有冗余备份，挂了还会有其他备用节点顶上。

但有了集群化(冗余)还不够，例如出现网络延迟而导致的服务假性宕机(实际上是因为网络延迟导致)，这时可能出现两台主机，所以还**需要通过 “自动故障转移” + “冗余”来实现系统的高可用**。



那么，了解了高并发和高可用，回到问题上。该如何设计呢？

分为以下八点：

1.系统拆分

2.Cache(缓存)

3.MQ

4.数据库拆分(分库分表)

5.读写分离( 集群 )

6.ElasticSearch

7.HTML 页面静态化

8.CDN加速



每个点来详细了解一下，首先是

①**系统拆分**，指的是将系统拆分成多个子系统，这里可以 通过  基于Springboot实现多个微服务系统的Springcloud。并且每个微服务单独连自己的数据库(除却金额、个人信息等可在各个微服务间共享的数据)。

②**缓存**，常见的一种优化方式，比较常用的缓存数据库是**Redis**。在数据库层上加一层缓存，减少对数据库的访问压力。**缓存中的数据都是存储在内存里的，而数据库中的数据是写在磁盘上的，访问内存肯定是比访问磁盘快的可不止一个数量级**。

③**MQ**，一类消息中间件。如RabbitMQ、ActiveMQ、Kafka、RocketMQ等。这里采用MQ主要处理的是**高并发写的场景**。应**考虑承载复杂的写业务逻辑的场景中，如何使用MQ来异步写，提高并发性**。

④**分库分表**，指的是 在表中数据量大的时候，数据查询等操作会变得缓慢，数据库拆分就会成为一个紧急的需求。分库分表的实现有两种方式：**第一种是垂直拆分，第二种是水平拆分**。

**水平拆分是把同一个表的数据按一定规则拆到不同的数据库中，每个库可以放在不同的服务器上**

**垂直切分**是指按照业务将表进行分类，分布到不同的数据库上面，这样也就将数据或者说压力分担到不同的库上面



⑤**读写分离**，考虑到大多数情况下读多写少，可以采用 主从模式，主机写入、从机读取。

⑥ **ElasticSearch**，简称es。es是分布式的，可以随便扩容，一些**比较简单的查询、统计类的操作**，可以考虑用 es 来承载，还有一些**全文搜索**类的操作，也可以考虑用 es 来承载。

⑦ **CDN加速**，任何一个互联网系统面向的用户都遍布于地球的每个角落，每个角落的请求到机房可用多种路径可选，正所谓条条大路通罗马，这里是条条路径通机房。其中有速度快的路径有慢的路径，如何选择最优路径，把每个角落的请求快速的传递到机房，这就是 CDN 的功能

⑧ **HTML页面静态化**，**最常见的优化方式，成本低不需要考虑硬件成本**。静态页面部署在 NGNIX 中，收到用户请求，Ngnix 不需要访问 Webapp 即可响应用户，减少应用渲染页面的时间，同时也降低了应用的压力









### 2.RPC框架了解吗？如果要让你设计一个RPC框架，你该怎么做？



