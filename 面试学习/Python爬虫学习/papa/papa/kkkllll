import scrapy
from urllib import parse
from papa.items import StockItme

class MySpider(scrapy.Spider):
    name = 'kkkllll'
    # 添加URL参数
    def __init__(self, category=None, *args, **kwargs):
        super(MySpider, self).__init__(*args, **kwargs)
        self.start_urls=['https://repository.duke.edu/dc/gamble?f%5Bcommon_model_name_ssi%5D%5B%5D=Item&per_page=100']

    # 获取url并访问
    def parse(self, response):
        post_urls= response.xpath("//*[@id=\"documents\"]/div/div/a/@href").extract()
        for post_url in post_urls:
            yield scrapy.Request(url=parse.urljoin(response.url, post_url),callback=self.parse_detail,dont_filter=True)

    # 打印
    def parse_detail(self, response):
        # title内容
        title_ = response.xpath("//*[@id=\"item-info\"]/dl/dt[1]/text()").extract()
        title_t = response.xpath("//*[@id=\"item-info\"]/dl/dd[1]/ul/li/text()").extract()

        # Alternative Title:
        atternative_ = response.xpath("//*[@id=\"item-info\"]/dl/dt[2]/text()").extract()
        atternative_t = response.xpath("//*[@id=\"item-info\"]/dl/dd[2]/ul/li/text()").extract()

        # date
        date_ = response.xpath("//*[@id=\"item-info\"]/dl/dt[3]/text()").extract()
        date_t = response.xpath("//*[@id=\"item-info\"]/dl/dd[3]/ul/li/text()").extract()

        # creator
        creator_ = response.xpath("//*[@id=\"item-info\"]/dl/dt[4]/text()").extract()
        creator_t = response.xpath("//*[@id=\"item-info\"]/dl/dd[4]/ul/li/a/text()").extract()

        # location
        location_ = response.xpath("//*[@id=\"item-info\"]/dl/dt[5]/text()").extract()
        location_t = response.xpath("//*[@id=\"item-info\"]/dl/dd[5]/ul/li/a/text()").extract()

        # format
        format_ = response.xpath("//*[@id=\"item-info\"]/dl/dt[6]/text()").extract()
        format_t = response.xpath("//*[@id=\"item-info\"]/dl/dd[6]/ul/li/a/text()").extract()

        # Digital Collection:
        dig_t = format_t = response.xpath("///*[@id=\"item-info\"]/dl/dd[7]/a/text()").extract()